{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "Pandas is another module that, like numPy, is widely used in the scientific community. We'll look at how it is commonly used to read in files to a Pandas _'dataframe'_ which is something like a cross between a 2D numPy array and a spreadsheet sheet (the Pandas 1D equivalent is called a _Series_). It allows the data to be processed and manipulted in many ways - we'll look at some of the basic methods used.\n",
    "\n",
    "We've provided a small CSV file called 'observatories_Demo.csv' which should be put into the same folder as this notebook. If this were opened in a spreadsheet it would look like this:\n",
    "\n",
    "![observatories.png](observatories.png)\n",
    "\n",
    "Notice that the first 2 rows are either a comment or blank. The 3rd row shows the data column names and the actual data starts on the 4th line.\n",
    "\n",
    "Let's read this in using Pandas and see how to perform some basic functions.\n",
    "\n",
    "First, do your imports and set up any other constants or Jupyter settings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read in the file to a pandas datframe.\n",
    "\n",
    "Things to note:\n",
    "\n",
    "We've told Pandas that the columns are delimted by ',' - actually this is the default but you could change this to any other character that is used in the file. (If it's space delimited use sep='\\s+')\n",
    "\n",
    "We've also told it where the data starts, starting with column headings, by using 'header=2'.\n",
    "\n",
    "At the end of this notebook there is a section which describes how you can get more control on which data you read in and which you leave out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('observatories-DEMO.csv', sep=',', header=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So what does it look like? just type the dataframe's name.\n",
    "\n",
    "Things to note:\n",
    "\n",
    "Pandas has recognised that the first actual line it comes to (after the 'header' lines have been skipped) is the actual names of the columns. \n",
    "\n",
    "It has automatically 'indexed' the rows (the numbers on the left) based on the order the rows appear in the file We'll be changing this later, indexing on a column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE\n",
    "\n",
    "Just using 'df' gives a nicely formatted output. Try running print(df) as an alternative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You can also just look at the first few or last few rows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADDING MORE DATA\n",
    "\n",
    "Lets add a row for Jodrell Bank radio observatory in Cheshire, UK. You'll need to set up a Dict object where the keys are the column identifiers and the values are the ...er... values!\n",
    "\n",
    "We can then append it to our datframe - and this produces a NEW dataframe (doesn't modify the currect one) which we can asign to a new variable. Note that we have to set the parameter 'ignore_index=True')\n",
    "\n",
    "A word of warning, becuase this method creates a completely new dataframe it can use considerable memory for large data sets. There are other, more economical (but oiften slower) ways. (df.loc[len(df)] = ['blah blah', 'BB', 53, 2, 100], modifies df insitu) RTFM.\n",
    "\n",
    "\n",
    "### Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'Observatory':'Jodrell Bank', 'short':'JB', \n",
    "           'lat':53.23625, 'long':-2.307139, 'altitude':77}\n",
    "\n",
    "df_mod = df.append(new_row, ignore_index=True)\n",
    "\n",
    "df_mod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns\n",
    "\n",
    "How about adding a column. You can add a column with a simple, default value like this:\n",
    "\n",
    "**`df['new_column_name'] = 42`**\n",
    "\n",
    "Probably more usefully, we'll add a column, named 'hemisphere', that indicates if the observtory is 'Southern' or 'Northern'. This is tricky but can be done based on numpy's '**`where()`**' function, which does a boolean comparison and returns its first or second parameter based on the boolean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod['hemisphere'] = np.where(df_mod['lat'] <0, 'Southern', 'Northern')\n",
    "df_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Writing the modified data back to disk\n",
    "\n",
    "You can, of course, now write this back to a file. Pandas makes this, as a meerkat might say, 'simples!'.\n",
    "\n",
    "The 'index=False' just ensures that you don't get a column with 0,1,2,3,... in the file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod.to_csv('observatories-MODIFIED.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCESSING SECTIONS OF YOUR DATA\n",
    "\n",
    "\n",
    "### Columns\n",
    "\n",
    "You can access a single column by using the name of the column. Like this:\n",
    "\n",
    "(Note that you can combine this with **`head()`** and **`tail()`** -  **`df['Observatory'].head())`**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod['Observatory']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note that, at the bottom of the listing, it shows this is an 'object'. In fact the object is a Pandas Series in this case. You could convert this to a numpy array (**`np.array(df_mod['Observatory'])`** or even a normal Python list (**`list(df_mod['Observatory'])`**).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE\n",
    "\n",
    "Display the last 3 rows of the 'short' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod['short'].tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rows\n",
    "\n",
    "Selecting rows is a little less intuitive. We'll look at using '**.iloc**' (which uses numerical indices) and logic based selections here.Then, later, after talking about indexing we'll show a further method, based on a modified index.\n",
    "\n",
    "**iloc**\n",
    "\n",
    "Firstly using **.iloc**. This is similar to using numPy slices and is something along the lines of datframe[startRow-1:endRow, startCol-1:endCol]  \n",
    "\n",
    "Let's look at finding rows 3 to 5 (Green Bank to PIRATE, indexed as 2,3 and 4 - Remember indices start at 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod.iloc[2:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Extending the 'slices' approach we can restrict the number of columns at the same time:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod.iloc[2:5,1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logic based selections**\n",
    "\n",
    "Now for the 'logic' based selection. For this we'll be using **loc**\n",
    "\n",
    "We might, for example, just want to use the Southern observatories:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod.loc[df_mod['lat'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(Note: actually **`df[df['lat'] <0]`** will also work just fine.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Or the ones that are at an altitude of over 4000 metres:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod.loc[(df_mod['altitude'] > 4000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE\n",
    "\n",
    "How would you get all the southern observatories over 4000m high? (HINT don't use 'and' you'll need to use '&')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod.loc[(df_mod['altitude'] > 4000) & (df['lat'] < 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # INDEXING\n",
    "\n",
    "At the moment, the row index is pretty much like any other list or array - starting at 0 and incrementing. But we can modify this by indexing on a column. Let's say we want to be able to get easy acces to data based on the 'short' column. This uses the '**`.set_index()`** function. (You can reindex 'inplace' by passing the parameter **`'inplace=True'`**)\n",
    "\n",
    "So, using our example and indexing on 'short' (**Note, the `drop=False` is important because if we don't do this and re-index later we'd loose the column name 'short'**) we get:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod.set_index('short', inplace=True, drop=False)\n",
    "df_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note that the index is now based on the short names\n",
    "\n",
    "This is useful because we can now acces rows more 'naturally'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod.loc['ARC',:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As we noted earlier, this doesn't look like a row - and it isn't. However, as before, you can easily turn it into a list or numPy array by using **`df.get_values()`** or **`np.array(df)`**. You can also access values from it using the attribute names shown ('Observatory', 'short', 'lat' etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_obj = df_mod.loc['ALMA',:]\n",
    "print('The longitude of', row_obj.Observatory, 'is', row_obj.long, 'degrees')\n",
    "print('It is a', row_obj.hemisphere, 'observatory')\n",
    "nump_row=row_obj.get_values()\n",
    "print('The numPy array is', nump_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single values**\n",
    "\n",
    "And, of course, you can get a single value from the DatFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod.loc['ARC','altitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE\n",
    "\n",
    "What is the name of the highest observatory and what are its coordinates (using North/South and W/E)\n",
    "\n",
    "HINT: \n",
    "\n",
    "1. Find the highest altitude (use the np.max() function on a row)\n",
    "2. use this to search and get the row\n",
    "3. retreive the lat and long\n",
    "4. do some string formating stuff \n",
    "5. print it out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get highest observatory\n",
    "alt_max = np.max(df_mod['altitude'])\n",
    "# Which row is this in?\n",
    "highest_row=df_mod.loc[df_mod['altitude']==alt_max]\n",
    "# use the attribute names. In each case a Series is returned with only a single item\n",
    "# hence we use the [0] to get this.\n",
    "lat = (float(highest_row.lat[0]))\n",
    "# and longitude\n",
    "lon = (float(highest_row.long[0]))\n",
    "# and the name\n",
    "nam = highest_row.Observatory[0]\n",
    "# Construct the latitude string - check if <0, get the string value of\n",
    "# the absolute value and add '-S' etc. accordingly\n",
    "if lat<0:\n",
    "    latval = str(abs(lat))+'-S'\n",
    "else:\n",
    "    latval = str(abs(lat))+'-N'\n",
    "if lon<0:\n",
    "    lonval = str(abs(lon))+'-W'\n",
    "else:\n",
    "    lonval = str(abs(lon))+'-`e'\n",
    "\n",
    "print('The highest observatory is', nam,'at', lonval, ' ', latval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# GETTING RID OF STUFF WE DON\"T WANT\n",
    "\n",
    "What if we don't want everything in the DataFrame? It is possible to get rid of (Drop in Pandas parlance) data.\n",
    "\n",
    "### Rows\n",
    "\n",
    "Use the **`.drop()`** function with a row name (if indexed) or numeric index if not. If it is indexed and you want to use a numberic index, use the **`df.index()`** function. We also need to specify which 'axis' is to be dropped. **`axis[0]`** refers ro a row (and **`axis[1]`** refers to a column - see later)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df_mod.drop('ERT',axis=0)\n",
    "df_drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_num = df_drop.drop(df_drop.index[9], axis=0)\n",
    "df_drop_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns\n",
    "\n",
    "are pretty much the same:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_col = df_drop_num.drop('altitude', axis=1)\n",
    "df_drop_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ROUNDUP\n",
    "\n",
    "So that is just a basic rundown of Pandas. It has many more features which are not touched on here, but these should be enough to get you started.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Just for fun - plotting data**\n",
    "\n",
    "See if you can see how it's done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data=df_mod.sort_values(by='altitude')['altitude']\n",
    "sorted_data.plot(kind='bar', color='r')\n",
    "plt.title('Observatories ranked by altitude')\n",
    "plt.ylabel('Altitude (m)')\n",
    "plt.xlabel('Observatory short name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Reading data from file, Getting more control\n",
    "\n",
    "Often we don't want to read all the data in - and pandas allows you to control this.\n",
    "\n",
    "Let's say we have a CSV file with the following column structure (This is actual data from a PIRATE observing run):\n",
    "\n",
    "![CSV file column headers](pirateHeaders.png)\n",
    "\n",
    "Obviously, some column widths have been collapsed for clarity, but the thing to note is that there are (19) columns headed 'rel_flux_Tn' (T2 - T20 and a corresponding set of columns headed 'rel_flux_err_Tn'. Now, say we're only interested in the firts set of data columns - can we restrict what we read in?\n",
    "\n",
    "The simplest way to do this is to specify the column indices we want to read in and this can be done by using the 'usecols' parameter and giving it a list of column indices. (note, this is a TAB delinited file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rel_flux_T2</th>\n",
       "      <th>rel_flux_T3</th>\n",
       "      <th>rel_flux_T4</th>\n",
       "      <th>rel_flux_T5</th>\n",
       "      <th>rel_flux_T6</th>\n",
       "      <th>rel_flux_T7</th>\n",
       "      <th>rel_flux_T8</th>\n",
       "      <th>rel_flux_T9</th>\n",
       "      <th>rel_flux_T10</th>\n",
       "      <th>rel_flux_T11</th>\n",
       "      <th>rel_flux_T12</th>\n",
       "      <th>rel_flux_T13</th>\n",
       "      <th>rel_flux_T14</th>\n",
       "      <th>rel_flux_T15</th>\n",
       "      <th>rel_flux_T16</th>\n",
       "      <th>rel_flux_T17</th>\n",
       "      <th>rel_flux_T18</th>\n",
       "      <th>rel_flux_T19</th>\n",
       "      <th>rel_flux_T20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.020331</td>\n",
       "      <td>1.195483</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>2.520743</td>\n",
       "      <td>1.309739</td>\n",
       "      <td>5.670653</td>\n",
       "      <td>11.200807</td>\n",
       "      <td>4.550661</td>\n",
       "      <td>1.196648</td>\n",
       "      <td>1.111401</td>\n",
       "      <td>0.630952</td>\n",
       "      <td>0.391320</td>\n",
       "      <td>0.498290</td>\n",
       "      <td>0.782992</td>\n",
       "      <td>0.234724</td>\n",
       "      <td>0.686370</td>\n",
       "      <td>3.164365</td>\n",
       "      <td>2.366509</td>\n",
       "      <td>6.907612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.958710</td>\n",
       "      <td>1.153409</td>\n",
       "      <td>0.490615</td>\n",
       "      <td>2.437191</td>\n",
       "      <td>1.303201</td>\n",
       "      <td>5.535183</td>\n",
       "      <td>10.819443</td>\n",
       "      <td>4.464953</td>\n",
       "      <td>1.160523</td>\n",
       "      <td>1.010679</td>\n",
       "      <td>0.577063</td>\n",
       "      <td>0.354256</td>\n",
       "      <td>0.491068</td>\n",
       "      <td>0.741796</td>\n",
       "      <td>0.262612</td>\n",
       "      <td>0.642608</td>\n",
       "      <td>3.073194</td>\n",
       "      <td>2.263287</td>\n",
       "      <td>6.753225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rel_flux_T2  rel_flux_T3  rel_flux_T4  rel_flux_T5  rel_flux_T6  \\\n",
       "0     1.020331     1.195483     0.512954     2.520743     1.309739   \n",
       "1     0.958710     1.153409     0.490615     2.437191     1.303201   \n",
       "\n",
       "   rel_flux_T7  rel_flux_T8  rel_flux_T9  rel_flux_T10  rel_flux_T11  \\\n",
       "0     5.670653    11.200807     4.550661      1.196648      1.111401   \n",
       "1     5.535183    10.819443     4.464953      1.160523      1.010679   \n",
       "\n",
       "   rel_flux_T12  rel_flux_T13  rel_flux_T14  rel_flux_T15  rel_flux_T16  \\\n",
       "0      0.630952      0.391320      0.498290      0.782992      0.234724   \n",
       "1      0.577063      0.354256      0.491068      0.741796      0.262612   \n",
       "\n",
       "   rel_flux_T17  rel_flux_T18  rel_flux_T19  rel_flux_T20  \n",
       "0      0.686370      3.164365      2.366509      6.907612  \n",
       "1      0.642608      3.073194      2.263287      6.753225  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pirate_data = pd.read_csv('Measurements_M13_Lum_00.xls', sep='\\t', \\\n",
    "                          usecols=[5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23])\n",
    "\n",
    "pirate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "But, what if we're going to be using data which has variable numbers of the data columns? We'll, usecols will also take 'generated' information. We'll use a 'lambda' function to do this.\n",
    "\n",
    "In this case - `lambda s: s[0:10]=='rel_flux_T'`\n",
    "\n",
    "This matches the first 10 letters in the column header (which is passed to the function) matches 'rel_flux_T'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rel_flux_T2</th>\n",
       "      <th>rel_flux_T3</th>\n",
       "      <th>rel_flux_T4</th>\n",
       "      <th>rel_flux_T5</th>\n",
       "      <th>rel_flux_T6</th>\n",
       "      <th>rel_flux_T7</th>\n",
       "      <th>rel_flux_T8</th>\n",
       "      <th>rel_flux_T9</th>\n",
       "      <th>rel_flux_T10</th>\n",
       "      <th>rel_flux_T11</th>\n",
       "      <th>rel_flux_T12</th>\n",
       "      <th>rel_flux_T13</th>\n",
       "      <th>rel_flux_T14</th>\n",
       "      <th>rel_flux_T15</th>\n",
       "      <th>rel_flux_T16</th>\n",
       "      <th>rel_flux_T17</th>\n",
       "      <th>rel_flux_T18</th>\n",
       "      <th>rel_flux_T19</th>\n",
       "      <th>rel_flux_T20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.020331</td>\n",
       "      <td>1.195483</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>2.520743</td>\n",
       "      <td>1.309739</td>\n",
       "      <td>5.670653</td>\n",
       "      <td>11.200807</td>\n",
       "      <td>4.550661</td>\n",
       "      <td>1.196648</td>\n",
       "      <td>1.111401</td>\n",
       "      <td>0.630952</td>\n",
       "      <td>0.391320</td>\n",
       "      <td>0.498290</td>\n",
       "      <td>0.782992</td>\n",
       "      <td>0.234724</td>\n",
       "      <td>0.686370</td>\n",
       "      <td>3.164365</td>\n",
       "      <td>2.366509</td>\n",
       "      <td>6.907612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.958710</td>\n",
       "      <td>1.153409</td>\n",
       "      <td>0.490615</td>\n",
       "      <td>2.437191</td>\n",
       "      <td>1.303201</td>\n",
       "      <td>5.535183</td>\n",
       "      <td>10.819443</td>\n",
       "      <td>4.464953</td>\n",
       "      <td>1.160523</td>\n",
       "      <td>1.010679</td>\n",
       "      <td>0.577063</td>\n",
       "      <td>0.354256</td>\n",
       "      <td>0.491068</td>\n",
       "      <td>0.741796</td>\n",
       "      <td>0.262612</td>\n",
       "      <td>0.642608</td>\n",
       "      <td>3.073194</td>\n",
       "      <td>2.263287</td>\n",
       "      <td>6.753225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rel_flux_T2  rel_flux_T3  rel_flux_T4  rel_flux_T5  rel_flux_T6  \\\n",
       "0     1.020331     1.195483     0.512954     2.520743     1.309739   \n",
       "1     0.958710     1.153409     0.490615     2.437191     1.303201   \n",
       "\n",
       "   rel_flux_T7  rel_flux_T8  rel_flux_T9  rel_flux_T10  rel_flux_T11  \\\n",
       "0     5.670653    11.200807     4.550661      1.196648      1.111401   \n",
       "1     5.535183    10.819443     4.464953      1.160523      1.010679   \n",
       "\n",
       "   rel_flux_T12  rel_flux_T13  rel_flux_T14  rel_flux_T15  rel_flux_T16  \\\n",
       "0      0.630952      0.391320      0.498290      0.782992      0.234724   \n",
       "1      0.577063      0.354256      0.491068      0.741796      0.262612   \n",
       "\n",
       "   rel_flux_T17  rel_flux_T18  rel_flux_T19  rel_flux_T20  \n",
       "0      0.686370      3.164365      2.366509      6.907612  \n",
       "1      0.642608      3.073194      2.263287      6.753225  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pirate_data = pd.read_csv('Measurements_M13_Lum_00.xls', sep='\\t', usecols=lambda s: s[0:10]=='rel_flux_T')\n",
    "\n",
    "pirate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So, the same result - but more flexible.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
